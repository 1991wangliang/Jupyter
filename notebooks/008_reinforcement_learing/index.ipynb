{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da68ad75-8fed-4f52-8fc4-103bb2145aea",
   "metadata": {},
   "source": [
    "pip install gym[classic_control]\n",
    "pip install pyglet\n",
    "# Install additional packages for visualization\n",
    "sudo apt-get install -y xvfb python-opengl \n",
    "pip install pyvirtualdisplay  \n",
    "pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "955ad8e9-4ffa-4cc8-bdbb-a87271a48b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 22:39:21.891189: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-02 22:39:22.014487: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-02 22:39:22.457822: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lorne/miniconda3/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-02 22:39:22.457883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lorne/miniconda3/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-02 22:39:22.457890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import gym\n",
    "import numpy as np\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import warnings\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "# Set seed for experiment reproducibility\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Small epsilon value for stabilizing division operations\n",
    "eps = np.finfo(np.float32).eps.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16364536-188e-49aa-abd0-08a6c78cc959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(tf.keras.Model):\n",
    "  \"\"\"Combined actor-critic network.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self, \n",
    "      num_actions: int, \n",
    "      num_hidden_units: int):\n",
    "    \"\"\"Initialize.\"\"\"\n",
    "    super().__init__()\n",
    "\n",
    "    self.common = layers.Dense(num_hidden_units, activation=\"relu\")\n",
    "    self.actor = layers.Dense(num_actions)\n",
    "    self.critic = layers.Dense(1)\n",
    "\n",
    "  def call(self, inputs: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    x = self.common(inputs)\n",
    "    return self.actor(x), self.critic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90830cd6-4ace-4875-afe9-bdc40b77d42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 22:39:23.682045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 22:39:23.711792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 22:39:23.711969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 22:39:23.712399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-02 22:39:23.712886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 22:39:23.713041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 22:39:23.713170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 22:39:24.133053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 22:39:24.133230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 22:39:24.133363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 22:39:24.133475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4950 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "num_actions = env.action_space.n  # 2\n",
    "num_hidden_units = 128\n",
    "\n",
    "model = ActorCritic(num_actions, num_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea047ec-28d2-459e-87fd-8c5264737a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap OpenAI Gym's `env.step` call as an operation in a TensorFlow function.\n",
    "# This would allow it to be included in a callable TensorFlow graph.\n",
    "\n",
    "def env_step(action: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "  \"\"\"Returns state, reward and done flag given an action.\"\"\"\n",
    "\n",
    "  state, reward, done, _ = env.step(action)\n",
    "  return (state.astype(np.float32), \n",
    "          np.array(reward, np.int32), \n",
    "          np.array(done, np.int32))\n",
    "\n",
    "\n",
    "def tf_env_step(action: tf.Tensor) -> List[tf.Tensor]:\n",
    "  return tf.numpy_function(env_step, [action], \n",
    "                           [tf.float32, tf.int32, tf.int32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0a5885-20a7-4d29-bfef-83cf97659431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(\n",
    "    initial_state: tf.Tensor,  \n",
    "    model: tf.keras.Model, \n",
    "    max_steps: int) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "  \"\"\"Runs a single episode to collect training data.\"\"\"\n",
    "\n",
    "  action_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "  values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "  rewards = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "\n",
    "  initial_state_shape = initial_state.shape\n",
    "  state = initial_state\n",
    "\n",
    "  for t in tf.range(max_steps):\n",
    "    # Convert state into a batched tensor (batch size = 1)\n",
    "    state = tf.expand_dims(state, 0)\n",
    "  \n",
    "    # Run the model and to get action probabilities and critic value\n",
    "    action_logits_t, value = model(state)\n",
    "  \n",
    "    # Sample next action from the action probability distribution\n",
    "    action = tf.random.categorical(action_logits_t, 1)[0, 0]\n",
    "    action_probs_t = tf.nn.softmax(action_logits_t)\n",
    "\n",
    "    # Store critic values\n",
    "    values = values.write(t, tf.squeeze(value))\n",
    "\n",
    "    # Store log probability of the action chosen\n",
    "    action_probs = action_probs.write(t, action_probs_t[0, action])\n",
    "  \n",
    "    # Apply action to the environment to get next state and reward\n",
    "    state, reward, done = tf_env_step(action)\n",
    "    state.set_shape(initial_state_shape)\n",
    "  \n",
    "    # Store reward\n",
    "    rewards = rewards.write(t, reward)\n",
    "\n",
    "    if tf.cast(done, tf.bool):\n",
    "      break\n",
    "\n",
    "  action_probs = action_probs.stack()\n",
    "  values = values.stack()\n",
    "  rewards = rewards.stack()\n",
    "  \n",
    "  return action_probs, values, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f61d91b2-218f-4c39-88b1-7a52b35b418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_return(\n",
    "    rewards: tf.Tensor, \n",
    "    gamma: float, \n",
    "    standardize: bool = True) -> tf.Tensor:\n",
    "  \"\"\"Compute expected returns per timestep.\"\"\"\n",
    "\n",
    "  n = tf.shape(rewards)[0]\n",
    "  returns = tf.TensorArray(dtype=tf.float32, size=n)\n",
    "\n",
    "  # Start from the end of `rewards` and accumulate reward sums\n",
    "  # into the `returns` array\n",
    "  rewards = tf.cast(rewards[::-1], dtype=tf.float32)\n",
    "  discounted_sum = tf.constant(0.0)\n",
    "  discounted_sum_shape = discounted_sum.shape\n",
    "  for i in tf.range(n):\n",
    "    reward = rewards[i]\n",
    "    discounted_sum = reward + gamma * discounted_sum\n",
    "    discounted_sum.set_shape(discounted_sum_shape)\n",
    "    returns = returns.write(i, discounted_sum)\n",
    "  returns = returns.stack()[::-1]\n",
    "\n",
    "  if standardize:\n",
    "    returns = ((returns - tf.math.reduce_mean(returns)) / \n",
    "               (tf.math.reduce_std(returns) + eps))\n",
    "\n",
    "  return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc0f4244-7550-4605-9445-f7dd95eaac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "\n",
    "def compute_loss(\n",
    "    action_probs: tf.Tensor,  \n",
    "    values: tf.Tensor,  \n",
    "    returns: tf.Tensor) -> tf.Tensor:\n",
    "  \"\"\"Computes the combined actor-critic loss.\"\"\"\n",
    "\n",
    "  advantage = returns - values\n",
    "\n",
    "  action_log_probs = tf.math.log(action_probs)\n",
    "  actor_loss = -tf.math.reduce_sum(action_log_probs * advantage)\n",
    "\n",
    "  critic_loss = huber_loss(values, returns)\n",
    "\n",
    "  return actor_loss + critic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1c57af-c4db-4828-9d77-10bf25484e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(\n",
    "    initial_state: tf.Tensor, \n",
    "    model: tf.keras.Model, \n",
    "    optimizer: tf.keras.optimizers.Optimizer, \n",
    "    gamma: float, \n",
    "    max_steps_per_episode: int) -> tf.Tensor:\n",
    "  \"\"\"Runs a model training step.\"\"\"\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "\n",
    "    # Run the model for one episode to collect training data\n",
    "    action_probs, values, rewards = run_episode(\n",
    "        initial_state, model, max_steps_per_episode) \n",
    "\n",
    "    # Calculate expected returns\n",
    "    returns = get_expected_return(rewards, gamma)\n",
    "\n",
    "    # Convert training data to appropriate TF tensor shapes\n",
    "    action_probs, values, returns = [\n",
    "        tf.expand_dims(x, 1) for x in [action_probs, values, returns]] \n",
    "\n",
    "    # Calculating loss values to update our network\n",
    "    loss = compute_loss(action_probs, values, returns)\n",
    "\n",
    "  # Compute the gradients from the loss\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "  # Apply the gradients to the model's parameters\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  episode_reward = tf.math.reduce_sum(rewards)\n",
    "\n",
    "  return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ed7524-dc96-424a-89b1-7086a8c4b528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset_array [-0.04636216  0.03522113 -0.00050814  0.0378525 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 22:39:25.729783: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: too many values to unpack (expected 4)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/ipykernel_18111/1817034971.py\", line 7, in env_step\n",
      "    state, reward, done, _ = env.step(action)\n",
      "\n",
      "ValueError: too many values to unpack (expected 4)\n",
      "\n",
      "\n",
      "  0%|          | 0/10000 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'while/PyFunc' defined at (most recent call last):\n    File \"/home/lorne/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/lorne/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_18111/2036984430.py\", line 22, in <cell line: 16>\n      episode_reward = int(train_step(initial_state, model, optimizer, gamma, max_steps_per_episode))\n    File \"/tmp/ipykernel_18111/1590885639.py\", line 16, in train_step\n      action_probs, values, rewards = run_episode(\n    File \"/tmp/ipykernel_18111/624883441.py\", line 14, in run_episode\n      for t in tf.range(max_steps):\n    File \"/tmp/ipykernel_18111/624883441.py\", line 32, in run_episode\n      state, reward, done = tf_env_step(action)\n    File \"/tmp/ipykernel_18111/1817034971.py\", line 14, in tf_env_step\n      return tf.numpy_function(env_step, [action],\nNode: 'while/PyFunc'\nDetected at node 'while/PyFunc' defined at (most recent call last):\n    File \"/home/lorne/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/lorne/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_18111/2036984430.py\", line 22, in <cell line: 16>\n      episode_reward = int(train_step(initial_state, model, optimizer, gamma, max_steps_per_episode))\n    File \"/tmp/ipykernel_18111/1590885639.py\", line 16, in train_step\n      action_probs, values, rewards = run_episode(\n    File \"/tmp/ipykernel_18111/624883441.py\", line 14, in run_episode\n      for t in tf.range(max_steps):\n    File \"/tmp/ipykernel_18111/624883441.py\", line 32, in run_episode\n      state, reward, done = tf_env_step(action)\n    File \"/tmp/ipykernel_18111/1817034971.py\", line 14, in tf_env_step\n      return tf.numpy_function(env_step, [action],\nNode: 'while/PyFunc'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: too many values to unpack (expected 4)\nTraceback (most recent call last):\n\n  File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_18111/1817034971.py\", line 7, in env_step\n    state, reward, done, _ = env.step(action)\n\nValueError: too many values to unpack (expected 4)\n\n\n\t [[{{node while/PyFunc}}]]\n\t [[while/body/_1/while/PyFunc/_48]]\n  (1) INVALID_ARGUMENT:  ValueError: too many values to unpack (expected 4)\nTraceback (most recent call last):\n\n  File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_18111/1817034971.py\", line 7, in env_step\n    state, reward, done, _ = env.step(action)\n\nValueError: too many values to unpack (expected 4)\n\n\n\t [[{{node while/PyFunc}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_1878]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreset_array\u001b[39m\u001b[38;5;124m'\u001b[39m,reset_array)\n\u001b[1;32m     20\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(reset_array, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 22\u001b[0m episode_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps_per_episode\u001b[49m\u001b[43m)\u001b[49m)    \n\u001b[1;32m     23\u001b[0m episodes_reward\u001b[38;5;241m.\u001b[39mappend(episode_reward)\n\u001b[1;32m     25\u001b[0m running_reward \u001b[38;5;241m=\u001b[39m statistics\u001b[38;5;241m.\u001b[39mmean(episodes_reward)\n",
      "File \u001b[0;32m/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'while/PyFunc' defined at (most recent call last):\n    File \"/home/lorne/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/lorne/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_18111/2036984430.py\", line 22, in <cell line: 16>\n      episode_reward = int(train_step(initial_state, model, optimizer, gamma, max_steps_per_episode))\n    File \"/tmp/ipykernel_18111/1590885639.py\", line 16, in train_step\n      action_probs, values, rewards = run_episode(\n    File \"/tmp/ipykernel_18111/624883441.py\", line 14, in run_episode\n      for t in tf.range(max_steps):\n    File \"/tmp/ipykernel_18111/624883441.py\", line 32, in run_episode\n      state, reward, done = tf_env_step(action)\n    File \"/tmp/ipykernel_18111/1817034971.py\", line 14, in tf_env_step\n      return tf.numpy_function(env_step, [action],\nNode: 'while/PyFunc'\nDetected at node 'while/PyFunc' defined at (most recent call last):\n    File \"/home/lorne/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/lorne/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/lorne/miniconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/lorne/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_18111/2036984430.py\", line 22, in <cell line: 16>\n      episode_reward = int(train_step(initial_state, model, optimizer, gamma, max_steps_per_episode))\n    File \"/tmp/ipykernel_18111/1590885639.py\", line 16, in train_step\n      action_probs, values, rewards = run_episode(\n    File \"/tmp/ipykernel_18111/624883441.py\", line 14, in run_episode\n      for t in tf.range(max_steps):\n    File \"/tmp/ipykernel_18111/624883441.py\", line 32, in run_episode\n      state, reward, done = tf_env_step(action)\n    File \"/tmp/ipykernel_18111/1817034971.py\", line 14, in tf_env_step\n      return tf.numpy_function(env_step, [action],\nNode: 'while/PyFunc'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: too many values to unpack (expected 4)\nTraceback (most recent call last):\n\n  File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_18111/1817034971.py\", line 7, in env_step\n    state, reward, done, _ = env.step(action)\n\nValueError: too many values to unpack (expected 4)\n\n\n\t [[{{node while/PyFunc}}]]\n\t [[while/body/_1/while/PyFunc/_48]]\n  (1) INVALID_ARGUMENT:  ValueError: too many values to unpack (expected 4)\nTraceback (most recent call last):\n\n  File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/lorne/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_18111/1817034971.py\", line 7, in env_step\n    state, reward, done, _ = env.step(action)\n\nValueError: too many values to unpack (expected 4)\n\n\n\t [[{{node while/PyFunc}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_1878]"
     ]
    }
   ],
   "source": [
    "\n",
    "min_episodes_criterion = 100\n",
    "max_episodes = 10000\n",
    "max_steps_per_episode = 1000\n",
    "\n",
    "# Cartpole-v0 is considered solved if average reward is >= 195 over 100 \n",
    "# consecutive trials\n",
    "reward_threshold = 195\n",
    "running_reward = 0\n",
    "\n",
    "# Discount factor for future rewards\n",
    "gamma = 0.99\n",
    "\n",
    "# Keep last episodes reward\n",
    "episodes_reward: collections.deque = collections.deque(maxlen=min_episodes_criterion)\n",
    "\n",
    "with tqdm.trange(max_episodes) as t:\n",
    "  for i in t:\n",
    "    reset_array = env.reset()[0]\n",
    "    initial_state = tf.constant(reset_array, dtype=tf.float32)\n",
    "   \n",
    "    episode_reward = int(train_step(initial_state, model, optimizer, gamma, max_steps_per_episode))    \n",
    "    episodes_reward.append(episode_reward)\n",
    "    \n",
    "    running_reward = statistics.mean(episodes_reward)\n",
    "   \n",
    "    t.set_description(f'Episode {i}')\n",
    "    t.set_postfix(episode_reward=episode_reward, running_reward=running_reward)\n",
    "  \n",
    "    # Show average episode reward every 10 episodes\n",
    "    if i % 10 == 0:\n",
    "      pass # print(f'Episode {i}: average reward: {avg_reward}')\n",
    "  \n",
    "    if running_reward > reward_threshold and i >= min_episodes_criterion:  \n",
    "        break\n",
    "\n",
    "print(f'\\nSolved at episode {i}: average reward: {running_reward:.2f}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2d6b05-cdcd-437a-b425-d04e508b0862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render an episode and save as a GIF file\n",
    "\n",
    "from IPython import display as ipythondisplay\n",
    "from PIL import Image\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "\n",
    "display = Display(visible=0, size=(400, 300))\n",
    "display.start()\n",
    "\n",
    "\n",
    "def render_episode(env: gym.Env, model: tf.keras.Model, max_steps: int): \n",
    "  screen = env.render(mode='rgb_array')\n",
    "  im = Image.fromarray(screen)\n",
    "\n",
    "  images = [im]\n",
    "  \n",
    "  state = tf.constant(env.reset(), dtype=tf.float32)\n",
    "  for i in range(1, max_steps + 1):\n",
    "    state = tf.expand_dims(state, 0)\n",
    "    action_probs, _ = model(state)\n",
    "    action = np.argmax(np.squeeze(action_probs))\n",
    "\n",
    "    state, _, done, _ = env.step(action)\n",
    "    state = tf.constant(state, dtype=tf.float32)\n",
    "\n",
    "    # Render screen every 10 steps\n",
    "    if i % 10 == 0:\n",
    "      screen = env.render(mode='rgb_array')\n",
    "      images.append(Image.fromarray(screen))\n",
    "  \n",
    "    if done:\n",
    "      break\n",
    "  \n",
    "  return images\n",
    "\n",
    "\n",
    "# Save GIF image\n",
    "images = render_episode(env, model, max_steps_per_episode)\n",
    "image_file = 'cartpole-v0.gif'\n",
    "# loop=0: loop forever, duration=1: play each frame for 1ms\n",
    "images[0].save(\n",
    "    image_file, save_all=True, append_images=images[1:], loop=0, duration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1b1d5-f060-4f97-8f0d-15b56135be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa95a1-93ba-4c60-b382-06985beb4471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
